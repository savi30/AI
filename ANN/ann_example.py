"""

this is an example
further work is still necessary in order for this code to work!!!

"""

from random import *
from math import *


class Neuron:
    def __init__(self, nI=0):
        self.noInputs = nI
        # MIN_W = -1, MAX_W = 1
        self.weights = [(random() * 2 - 1) for k in range(self.noInputs)]
        self.output = 0
        self.err = 0

    def activate(self, info):
        net = 0.0
        for i in range(self.noInputs):
            net += info[i] * self.weights[i]
        self.output = net  # for linear activation
        # self.output = 1 / (1.0 + exp(-net));	#for sigmoidal activation

    def setErr(val):
        self.err = val  # for linear activation
        # self.err = self.output * (1 â self.output) * val
        # for sigmoidal activation


class Layer:
    def __init__(self, noN=0, noIn=0):
        self.noNeurons = noN
        self.neurons = [Neuron(noIn) for k in range(self.noNeurons)]


class Network:
    def __init__(self, m=0, r=0, p=0, h=0):
        self.noInputs = m
        self.noOutputs = r
        self.noHiddenLayers = p
        self.noNeuronsPerHiddenLayer = h
        self.layers = [Layer(self.noInputs, 0)]
        self.layers += [Layer(self.noNeuronsPerHiddenLayer, self.noInputs)]
        self.layers += [Layer(self.noNeuronsPerHiddenLayer,
                              self.noNeuronsPerHiddenLayer) for k in
                        range(self.noHiddenLayers - 1)]
        self.layers += [Layer(self.noOutputs, self.noNeuronsPerHiddenLayer)]

    def activate(self, inputs):
        i = 0
        for n in self.layers[0]:
            n.output = inputs[i]
            i += 1
        for l in range(1, self.noHiddenLayers + 1):
            for n in layers[l]:
                info = []
                for i in range(n.noInputs):
                    info.append(self.layers[l - 1].neurons[i].output)
                n.activate(info)

    def errorsBackpropagate(self, err):
        for l in range(self.noHiddenLayers + 1, 1, -1):
            i = 0
            for n1 in self.layers[l]:
                if (l == self.noHiddenLayers + 1):
                    n1.err(err[i])
                else:
                    sumErr = 0.0
                    for n2 in self.layers[l + 1]:
                        sumErr += n2.weight[i] * n2.err
                    n1.err = sumErr
                for j in range(n1.noInputs):
                    netWeight = n1.weight[j] + LEAR_RATE * n1.err() * self.layers[l - 1].neurons[j].output
                    n1.weight[j] = netWeight
                i += 1

    def errorComputationRegression(self, target, err):
        globalErr = 0.0
        for i in range(self.layers[self.noHiddenLayers + 1].noNeurons):
            err.append(target[i] - self.layers[self.noHiddenLayers + 1].neurons[i].output)
            globalErr += err[i] * err[i]
        return (globalErr)

    def errorComputationClassification(self, target, noLabels, err):
        # normalise the output of neurons from the output layer (softmax transformation;
        # sum of transformed outputs is 1, each transformed output behaves like a probability)
        transfOutputs = []
        maxx = self.layers[self.noHiddenLayers + 1].neurons[0].output
        for i in range(1, noLabes):
            if (self.layers[self.noHiddenLayers + 1].neurons[i].output > maxx):
                maxx = layers[noHiddenLayers + 1].neurons[i].output
        sumExp = 0.0
        for i in range(1, noLabes):
            sumExp += exp(self.layers[self.noHiddenLayers + 1].neurons[i].output - maxx)
        for i in range(1, noLabes):
            transfOutputs.append(exp(self.layers[self.noHiddenLayers + 1].neurons[i].output - maxx) / sumExp)
        maxx = transfOutputs[0]
        computedlabel = 1
        for i in range(1, noLabes):
            if (transfOutputs[i] > maxx):
                maxx = transfOutputs[i]
                computedlabel = i + 1
        if (target == computedlabel):
            err[0] = 0
        else:
            err[0] = 1
        globalErr = err[0]
        return globalErr

    def checkGlobalErr(self, err):
        # regression
        error = sum(err)
        if (abs(error) < 1 / (10 ** 8)):
            return True
        else:
            return False
        """    
        #clasification
        correct=sum(err)
        error=correct/len(err)
        if error>0.95:
            return True
        else:
            return False
        """

    def learning(self, inData, outData):
        stopCondition = False
        epoch = 0
        globalErr = []
        while ((not stopCondition) and (epoch < EPOCH_LIMIT)):
            globalErr = []
            # for each training example
            for d in range(len(inData)):
                self.activate(inData[d])  # activate all the neurons; propagate forward the signal
                err = []  # backpropagate the error of neurons from the output layer
                globalErr[d] = self.errorComputationRegression(outData[d], err)
                # globalErr[d] = self.errorComputationClassification(outData[d][0], 2, err)
                self.errorsBackPropagate(err)
            stopCondition = self.checkGlobalErr(globalErr)
            epoch += 1

    def testing(self, inData, outData):
        globalErr = []
        for d in range(len(inData)):  # for each testing example
            self.activate(inData[d])  # activate all the neurons; propagate forward the signal
            err = []  # compute the error of neurons from the output layer
            globalErr[d] = self.errorComputationRegression(outData[d], err)
            # globalErr[d] = self.errorComputationClassification(outData[d][0], 2, err)


def readData(noExamples, noFeatures, noOutputs, inData, outData, fileName):
    pass


def normaliseData(noExamples, noFeatures, trainData, noTestExamples, testData):
    # statistical normalisation
    for j in range(noFeatures):
        summ = 0.0
        for i in range(noExamples):
            summ += trainData[i][j]
        mean = summ / noEamples
        squareSum = 0.0
        for i in range(noExamples):
            squareSum += (trainData[i][j] - mean) ** 2;
        deviation = sqrt(squareSum / noExamples)
        for i in range(noExamples):
            trainData[i][j] = (trainData[i][j] - mean) / deviation
        for i in range(noTestExamples):
            testData[i][j] = (testData[i][j] - mean) / deviation
    # min-max normalization
    """
    for j in range(noFeatures):
        minn=min([trainData[i][j] for i in range(noExamples)])
        maxx=max([trainData[i][j] for i in range(noExamples)])
        for i in range(noExamples):
            trainData[i][j]=LIM_MIN+trainData[i][j]*(LIM_MAX-LIM_MIN)/(maxx - minn)
         for i in range(noTestExamples):
            testData[i][j]=LIM_MIN+testData[i][j]*(LIM_MAX-LIM_MIN)/(maxx - minn)
    """


def main_ANN():
    # to do some variables initialisations
    readData(noTrainExamples, noFeatures, noOutputs, inTrainData, outTrainData, "dataRegression.train")
    readData(noTestExamples, noFeatures, noOutputs, inTestData, outTestData, "dataRegression.test")

    # readData(noTrainExamples, noFeatures, noOutputs, inTrainData, outTrainData, "dataClassification.train")
    # readData(noTestExamples, noFeatures, noOutputs, inTestData, outTestData, "dataClassification.test")

    net = Network(noFeatures, noOutputs, 1, 2)

    # normaliseData(noTrainExamples, noFeatures, inTrainData, noTestExamples, inTestData)
    # net = Network(noFeatures, noOutputs, 1, 2)

    net.learning(inTrainData, outTrainData)
    net.testing(inTestData, outTestData)